{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pi/.local/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: \n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(name, img):\n",
    "    cv2.imshow(name, img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def sharpen(img, sigma=100):    \n",
    "    # sigma = 5、15、25\n",
    "    blur_img = cv2.GaussianBlur(img, (0, 0), sigma)\n",
    "    usm = cv2.addWeighted(img, 1.5, blur_img, -0.5, 0)\n",
    "    return usm\n",
    "\n",
    "def cropImg(img, boxes, size):\n",
    "    (H, W) = size\n",
    "    h_s = H/608\n",
    "    w_s = W/608\n",
    "    x,y,w,h = boxes\n",
    "    crop_img = img[y:y+h, x:x+w]\n",
    "    mx = max(crop_img.shape[:2])\n",
    "    scale = 300/mx\n",
    "    crop_img = cv2.resize(crop_img, None, fx=scale*w_s, fy=scale*h_s)\n",
    "    return crop_img\n",
    "\n",
    "def OCR(crop_img):\n",
    "    # crop_img = Image.fromarray(cv2.cvtColor(crop_img, cv2.COLOR_BGR2RGB))\n",
    "    # # crop_img = Image.open('car.jpg')\n",
    "    # text = pytesseract.image_to_string(crop_img, lang='eng')\n",
    "    # print(text)\n",
    "    reader = easyocr.Reader(['en'])\n",
    "    result = reader.readtext('croped.jpg')\n",
    "    print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "weight_path = r\"./yolov4/yolov4-tiny-obj_best.weights\"\n",
    "cfg_path = r\"./yolov4/yolov4-tiny-obj.cfg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNet(weight_path, cfg_path)\n",
    "model = cv2.dnn_DetectionModel(net)\n",
    "model.setInputParams(size=(608, 608), scale=1/255, swapRB=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(375, 500, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "Canceled future for execute_request message before replies were done",
     "output_type": "error",
     "traceback": [
      "Error: Canceled future for execute_request message before replies were done",
      "at t.KernelShellFutureHandler.dispose (/home/pi/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1204175)",
      "at /home/pi/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1223227",
      "at Map.forEach (<anonymous>)",
      "at v._clearKernelState (/home/pi/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1223212)",
      "at v.dispose (/home/pi/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1216694)",
      "at /home/pi/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:533674",
      "at t.swallowExceptions (/home/pi/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:913059)",
      "at dispose (/home/pi/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:533652)",
      "at t.RawSession.dispose (/home/pi/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:537330)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (node:internal/process/task_queues:96:5)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "img_foloer = './images/'\n",
    "img_list = ['car2.jpg', 'car1.jpg', 'test.jpg']\n",
    "for i in range(1):\n",
    "    img = cv2.imread(img_foloer+img_list[i])\n",
    "    print(img.shape)\n",
    "    size = img.shape[:2]\n",
    "    img = cv2.resize(img, (608, 608), interpolation=cv2.INTER_AREA)\n",
    "    classes, confidence, [boxes] = model.detect(img, 0.3, 0.2)\n",
    "    crop_img = cropImg(img, boxes, size)\n",
    "    # crop_img = cv2.cvtColor(crop_img, cv2.COLOR_BGR2GRAY)\n",
    "    # ret, crop_img = cv2.threshold(crop_img, 100, 255, cv2.THRESH_BINARY_INV)\n",
    "    show_img('croped', crop_img)\n",
    "    cv2.imwrite('croped.jpg', crop_img)\n",
    "    OCR(crop_img)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fe2063b89a2debb28b6e56346d086f997907e640acc2ebfa1e0dbe42a035f839"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ES_final')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
